import os
import sys
import json
import pandas as pd
import numpy as np
import torch
import argparse
from datetime import datetime

# Ajouter le chemin du projet pour les imports
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# Import modifi√© pour r√©soudre l'erreur
from utils.body_motion_predictor import MLBodyPredictor, BodyMotionNetwork
# Fix import issue by creating a local implementation
def convert_imu_csv_to_json(csv_path, json_output_path):
    """Convertit les donn√©es IMU de CSV vers JSON."""
    print(f"üìä D√©but de conversion CSV ‚Üí JSON: {os.path.basename(csv_path)}")
    
    try:
        # Charger le fichier CSV
        print(f"   ‚î£ Lecture du fichier CSV...")
        df = pd.read_csv(csv_path)
        df.columns = df.columns.str.strip()  # Supprimer les espaces dans les noms de colonnes
        print(f"   ‚î£ CSV charg√© avec succ√®s: {len(df)} lignes trouv√©es")
        
        # Mapping capteur -> partie du corps
        sensor_map = {
            1: "torso",
            2: "forearm_l",
            3: "forearm_r",
            4: "calves_l",
            5: "calves_r",
            6: "head"
        }
        
        # Cr√©ation de la structure
        print(f"   ‚î£ Extraction des quaternions pour {len(sensor_map)} capteurs...")
        imu_data = []
        
        for _, row in df.iterrows():
            frame = {}
            for sensor_id, body_part in sensor_map.items():
                try:
                    w = float(row[f"QuatW_{sensor_id}"])
                    x = float(row[f"QuatX_{sensor_id}"])
                    y = float(row[f"QuatY_{sensor_id}"])
                    z = float(row[f"QuatZ_{sensor_id}"])
                    frame[body_part] = [round(w, 6), round(x, 6), round(y, 6), round(z, 6)]
                except (KeyError, ValueError) as e:
                    continue
            imu_data.append(frame)
        
        # Format final
        output = {
            "IMU": imu_data,
            "EMG": [],
            "pMMG": []
        }
        
        # Sauvegarde du JSON
        print(f"   ‚î£ Sauvegarde en JSON: {len(imu_data)} frames")
        with open(json_output_path, "w") as f:
            json.dump(output, f, indent=2)
        
        print(f"   ‚îó Conversion termin√©e ‚úÖ")
        return True
    except Exception as e:
        print(f"   ‚îó ERREUR pendant la conversion: {e} ‚ùå")
        return False

class AutoModelTrainer:
    """Classe pour automatiser l'entra√Ænement du mod√®le de pr√©diction de mouvement."""
    
    def __init__(self, csv_dir=None, json_dir=None, output_dir=None):
        """
        Initialise l'entra√Æneur automatique de mod√®le.
        
        Args:
            csv_dir: R√©pertoire contenant les fichiers CSV des donn√©es de capteurs
            json_dir: R√©pertoire o√π stocker les fichiers JSON convertis
            output_dir: R√©pertoire o√π sauvegarder le mod√®le entra√Æn√©
        """
        print("\nüîß INITIALISATION DE L'ENTRA√éNEUR AUTOMATIQUE")
        # Configuration des chemins
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.csv_dir = csv_dir or os.path.join(self.base_dir, 'machinelearning')
        self.json_dir = json_dir or os.path.join(self.base_dir, 'data', 'recordings')
        self.output_dir = output_dir or os.path.join(self.base_dir, 'data')
        
        print(f"   ‚î£ Dossier CSV: {self.csv_dir}")
        print(f"   ‚î£ Dossier JSON: {self.json_dir}")
        print(f"   ‚î£ Dossier de sortie: {self.output_dir}")
        
        # Cr√©er les r√©pertoires s'ils n'existent pas
        os.makedirs(self.json_dir, exist_ok=True)
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Ajouter un r√©pertoire pour les visualisations d'entra√Ænement
        self.viz_dir = os.path.join(self.output_dir, 'training_viz')
        os.makedirs(self.viz_dir, exist_ok=True)
        print(f"   ‚î£ Dossier de visualisation: {self.viz_dir}")
        
        # Configuration du mapping des capteurs
        self.sensor_map = {
            1: "torso",
            2: "forearm_l",
            3: "forearm_r",
            4: "calves_l",
            5: "calves_r",
            6: "head"
        }
        
        # Liste des parties du corps pour l'entra√Ænement
        self.body_parts_order = [
            'head', 'neck', 'torso', 'deltoid_l', 'biceps_l', 'forearm_l', 'left_hand',
            'deltoid_r', 'biceps_r', 'forearm_r', 'right_hand', 'hip',
            'quadriceps_l', 'calves_l', 'left_foot', 'quadriceps_r', 'calves_r', 'right_foot',
            'glutes_l', 'glutes_r'
        ]
        print(f"   ‚î£ Configuration: {len(self.body_parts_order)} parties du corps, {len(self.sensor_map)} capteurs IMU")
        
        # Parties du corps surveill√©es par des IMUs
        self.monitored_parts = list(self.sensor_map.values())
        
        # √âtat interne
        self.csv_files = []
        self.json_files = []
        self.training_data = None
        print(f"   ‚îó Initialisation termin√©e ‚úÖ")
    
    def find_csv_files(self):
        """Recherche tous les fichiers CSV dans le r√©pertoire sp√©cifi√©."""
        print("\nüîç RECHERCHE DES FICHIERS CSV")
        print(f"   ‚î£ Dossier cible: {self.csv_dir}")
        self.csv_files = []
        
        if os.path.exists(self.csv_dir):
            for filename in os.listdir(self.csv_dir):
                if filename.endswith('.csv'):
                    self.csv_files.append(os.path.join(self.csv_dir, filename))
        
        if not self.csv_files:
            print("   ‚îó ATTENTION: Aucun fichier CSV trouv√©. ‚ö†Ô∏è")
        else:
            print(f"   ‚î£ Trouv√© {len(self.csv_files)} fichiers CSV:")
            for i, file in enumerate(self.csv_files, 1):
                print(f"   ‚îÉ  {i}. {os.path.basename(file)}")
            print(f"   ‚îó Recherche termin√©e ‚úÖ")
        
        return self.csv_files
    
    def convert_all_csv_to_json(self):
        """Convertit tous les fichiers CSV trouv√©s en JSON."""
        print("\nüîÑ CONVERSION CSV ‚Üí JSON")
        if not self.csv_files:
            print("   ‚î£ Aucun fichier CSV trouv√©, lancement de la recherche...")
            self.find_csv_files()
            
        if not self.csv_files:
            print("   ‚îó ERREUR: Aucun fichier √† convertir. ‚ùå")
            return []
        
        print(f"   ‚î£ D√©but de la conversion de {len(self.csv_files)} fichiers vers {self.json_dir}")
        self.json_files = []
        
        for i, csv_file in enumerate(self.csv_files, 1):
            base_name = os.path.basename(csv_file).split('.')[0]
            json_file = os.path.join(self.json_dir, f"{base_name}.json")
            
            print(f"\n   ‚î£ [{i}/{len(self.csv_files)}] Conversion de {base_name}.csv")
            try:
                success = convert_imu_csv_to_json(csv_file, json_file)
                if success:
                    self.json_files.append(json_file)
                    print(f"      ‚îó Fichier JSON cr√©√©: {os.path.basename(json_file)}")
            except Exception as e:
                print(f"      ‚îó ERREUR pendant la conversion: {e} ‚ùå")
        
        print(f"\n   ‚îó Conversion termin√©e: {len(self.json_files)}/{len(self.csv_files)} fichiers convertis ‚úÖ")
        return self.json_files
    
    def load_json_data(self):
        """Charge les donn√©es JSON pour l'entra√Ænement."""
        print("\nüìÇ CHARGEMENT DES DONN√âES JSON")
        if not self.json_files and os.path.exists(self.json_dir):
            print(f"   ‚î£ Recherche de fichiers JSON dans {self.json_dir}")
            self.json_files = [
                os.path.join(self.json_dir, f) for f in os.listdir(self.json_dir)
                if f.endswith('.json')
            ]
        
        if not self.json_files:
            print("   ‚îó ERREUR: Aucun fichier JSON trouv√© pour l'entra√Ænement. ‚ùå")
            return None
        
        print(f"   ‚î£ Chargement de {len(self.json_files)} fichiers JSON")
        sequences = []
        
        for i, json_file in enumerate(self.json_files, 1):
            print(f"   ‚î£ [{i}/{len(self.json_files)}] Chargement de {os.path.basename(json_file)}")
            try:
                with open(json_file, 'r') as f:
                    data = json.load(f)
                
                if 'IMU' in data and len(data['IMU']) > 0:
                    sequences.append(data['IMU'])
                    print(f"      ‚îó Charg√© {len(data['IMU'])} frames ‚úÖ")
                else:
                    print(f"      ‚îó ATTENTION: Aucune donn√©e IMU trouv√©e dans le fichier ‚ö†Ô∏è")
            except Exception as e:
                print(f"      ‚îó ERREUR lors du chargement: {e} ‚ùå")
        
        total_frames = sum(len(s) for s in sequences)
        print(f"\n   ‚îó Chargement termin√©: {len(sequences)} s√©quences, {total_frames} frames au total ‚úÖ")
        return sequences
    
    def preprocess_data(self, sequences):
        """Pr√©pare les donn√©es pour l'entra√Ænement du mod√®le."""
        print("\nüîß PR√âTRAITEMENT DES DONN√âES")
        if not sequences:
            print("   ‚îó ERREUR: Aucune s√©quence √† pr√©traiter. ‚ùå")
            return None, None
        
        print(f"   ‚î£ Pr√©paration de {sum(len(seq) for seq in sequences)} frames pour l'entra√Ænement")
        inputs = []
        targets = []
        
        total_frames = sum(len(seq) - 1 for seq in sequences)
        processed_frames = 0
        
        print(f"   ‚î£ Extraction des paires d'entr√©e/sortie (frame actuelle ‚Üí frame suivante)")
        for seq_idx, sequence in enumerate(sequences, 1):
            print(f"   ‚î£ S√©quence {seq_idx}/{len(sequences)}: {len(sequence)} frames")
            for i in range(len(sequence) - 1):
                # Frame actuelle -> entr√©e
                current_frame = sequence[i]
                # Frame suivante -> cible √† pr√©dire
                next_frame = sequence[i + 1]
                
                # Pr√©parer l'entr√©e: quaternions des parties surveill√©es
                input_data = []
                for part in self.monitored_parts:
                    if part in current_frame:
                        input_data.extend(current_frame[part])
                    else:
                        # Si la partie n'est pas dans les donn√©es, ajouter quaternion identit√©
                        input_data.extend([1.0, 0.0, 0.0, 0.0])
                
                # S'assurer que l'entr√©e a la bonne taille (6 IMUs x 4 composantes)
                if len(input_data) < 24:
                    input_data.extend([0.0] * (24 - len(input_data)))
                elif len(input_data) > 24:
                    input_data = input_data[:24]
                
                # Pr√©parer la sortie: quaternions de toutes les parties du corps
                target_data = []
                for part in self.body_parts_order:
                    if part in next_frame:
                        target_data.extend(next_frame[part])
                    else:
                        # Si la partie n'est pas dans les donn√©es, ajouter quaternion identit√©
                        target_data.extend([1.0, 0.0, 0.0, 0.0])
                
                # S'assurer que la cible a la bonne taille (20 parties x 4 composantes)
                if len(target_data) < 80:
                    target_data.extend([0.0] * (80 - len(target_data)))
                elif len(target_data) > 80:
                    target_data = target_data[:80]
                
                inputs.append(input_data)
                targets.append(target_data)
                
                processed_frames += 1
                if processed_frames % 1000 == 0 or processed_frames == total_frames:
                    print(f"   ‚îÉ  Progression: {processed_frames}/{total_frames} frames ({processed_frames/total_frames*100:.1f}%)")
        
        # Convertir en tensors PyTorch
        if inputs and targets:
            print(f"   ‚î£ Conversion en tenseurs PyTorch...")
            inputs_tensor = torch.tensor(inputs, dtype=torch.float32)
            targets_tensor = torch.tensor(targets, dtype=torch.float32)
            print(f"   ‚î£ Dimensions: entr√©e {inputs_tensor.shape}, sortie {targets_tensor.shape}")
            
            # Garder une r√©f√©rence aux donn√©es
            self.training_data = (inputs_tensor, targets_tensor)
            
            print(f"   ‚îó Pr√©traitement termin√©: {inputs_tensor.shape[0]} exemples d'entra√Ænement ‚úÖ")
            return inputs_tensor, targets_tensor
        else:
            print("   ‚îó ERREUR: Aucune donn√©e √† pr√©traiter. ‚ùå")
            return None, None
    
    def train_model(self, epochs=100, batch_size=32, learning_rate=0.001, use_gpu=True, model_path=None):
        """Entra√Æne le mod√®le avec les donn√©es pr√©trait√©es."""
        print("\nüöÄ ENTRA√éNEMENT DU MOD√àLE")
        # Charger et pr√©traiter les donn√©es si n√©cessaire
        if self.training_data is None:
            print("   ‚î£ Pas de donn√©es pr√©trait√©es, chargement...")
            sequences = self.load_json_data()
            if sequences:
                print("   ‚î£ Pr√©traitement des donn√©es...")
                self.preprocess_data(sequences)
        
        if self.training_data is None:
            print("   ‚îó ERREUR: Pas de donn√©es d'entra√Ænement disponibles. ‚ùå")
            return False
        
        inputs_tensor, targets_tensor = self.training_data
        
        # Initialiser le pr√©dicteur de mouvement
        use_gpu = use_gpu and torch.cuda.is_available()
        device_str = "GPU" if use_gpu else "CPU"
        print(f"   ‚î£ D√©but de l'entra√Ænement sur {device_str} ({inputs_tensor.shape[0]} exemples)")
        print(f"   ‚î£ Configuration: {epochs} epochs, batch size {batch_size}, learning rate {learning_rate}")
        
        print("   ‚î£ Initialisation du mod√®le...")
        predictor = MLBodyPredictor(model_path if model_path else None)
        
        # Entra√Æner le mod√®le
        print(f"   ‚î£ Lancement de l'entra√Ænement ({datetime.now().strftime('%H:%M:%S')})")
        start_time = datetime.now()
        success = predictor.train_model(
            (inputs_tensor, targets_tensor), 
            epochs=epochs, 
            batch_size=batch_size, 
            learning_rate=learning_rate
        )
        
        training_time = datetime.now() - start_time
        print(f"   ‚î£ Entra√Ænement termin√© en {training_time.total_seconds():.1f} secondes")
        
        if success:
            # Sauvegarder le mod√®le
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = os.path.join(self.output_dir, f"motion_model_{timestamp}.pth")
            standard_path = os.path.join(self.output_dir, "motion_model.pth")
            # Ajouter le chemin pour training_viz
            viz_path = os.path.join(self.viz_dir, "motion_model.pth")
            
            if predictor.save_model(output_path):
                print(f"Mod√®le sauvegard√© √† {output_path}")
                
                # Copier vers les chemins standards
                import shutil
                shutil.copy2(output_path, standard_path)
                print(f"Mod√®le copi√© vers le chemin standard: {standard_path}")
                
                # Ajouter une copie dans training_viz
                shutil.copy2(output_path, viz_path)
                print(f"Mod√®le copi√© vers training_viz: {viz_path}")
                
                return True
        else:
            print("   ‚îó ERREUR: √âchec de l'entra√Ænement du mod√®le. ‚ùå")
        
        return False
    
    def run_full_pipeline(self, epochs=100, batch_size=32, learning_rate=0.001, use_gpu=True, model_path=None):
        """Ex√©cute le pipeline complet: conversion, chargement, pr√©traitement, entra√Ænement."""
        print("\nüîÑ D√âMARRAGE DU PIPELINE COMPLET D'ENTRA√éNEMENT")
        print("=" * 80)
        
        start_time = datetime.now()
        print(f"üìÖ Date et heure de d√©but: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # 1. Convertir les donn√©es CSV en JSON
        print("\nüìä √âTAPE 1: CONVERSION DES FICHIERS CSV EN JSON")
        self.convert_all_csv_to_json()
        
        # 2. Charger les donn√©es JSON
        print("\nüìã √âTAPE 2: CHARGEMENT DES DONN√âES JSON")
        sequences = self.load_json_data()
        
        # 3. Pr√©traiter les donn√©es
        if sequences:
            print("\nüîß √âTAPE 3: PR√âTRAITEMENT DES DONN√âES")
            inputs, targets = self.preprocess_data(sequences)
            
            # 4. Entra√Æner le mod√®le
            if inputs is not None and targets is not None:
                print("\nüß† √âTAPE 4: ENTRA√éNEMENT DU MOD√àLE")
                success = self.train_model(epochs, batch_size, learning_rate, use_gpu, model_path)
                
                total_time = datetime.now() - start_time
                print("\n=" * 80)
                if success:
                    print(f"\n‚úÖ PIPELINE D'ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS")
                    print(f"‚è±Ô∏è  Temps total: {total_time.total_seconds():.1f} secondes ({total_time})")
                    print(f"üìÇ Mod√®le sauvegard√© dans: {self.output_dir}")
                else:
                    print(f"\n‚ùå √âCHEC DE L'ENTRA√éNEMENT DU MOD√àLE")
                    print(f"‚è±Ô∏è  Temps √©coul√©: {total_time.total_seconds():.1f} secondes ({total_time})")
            else:
                print("\n‚ùå √âCHEC DU PR√âTRAITEMENT DES DONN√âES")
        else:
            print("\n‚ùå AUCUNE DONN√âE DISPONIBLE POUR L'ENTRA√éNEMENT")
        
        print("\n=" * 80)

def main():
    parser = argparse.ArgumentParser(description="Entra√Æne le mod√®le de pr√©diction de mouvement")
    parser.add_argument('--csv_dir', help="R√©pertoire contenant les fichiers CSV", default=None)
    parser.add_argument('--json_dir', help="R√©pertoire o√π stocker les JSON convertis", default=None)
    parser.add_argument('--output_dir', help="R√©pertoire de sortie pour le mod√®le", default=None)
    parser.add_argument('--epochs', type=int, help="Nombre d'epochs d'entra√Ænement", default=100)
    parser.add_argument('--batch_size', type=int, help="Taille des batchs d'entra√Ænement", default=32)
    parser.add_argument('--lr', type=float, help="Taux d'apprentissage", default=0.001)
    parser.add_argument('--cpu', action='store_true', help="Forcer l'utilisation du CPU (d√©faut: GPU si disponible)")
    parser.add_argument('--continue_training', action='store_true', 
                        help="Continuer l'entra√Ænement √† partir du mod√®le existant")
    parser.add_argument('--model_path', 
                        help="Chemin vers un mod√®le sp√©cifique √† charger (si --continue_training)")
    parser.add_argument('--fresh_start', action='store_true',
                        help="D√©marrer un entra√Ænement √† partir de z√©ro (ignorer mod√®le existant)")
    
    args = parser.parse_args()
    
    print("\n" + "=" * 80)
    print("ü§ñ PROGRAMME D'ENTRA√éNEMENT AUTOMATIS√â DU MOD√àLE DE PR√âDICTION DE MOUVEMENT")
    print("=" * 80)
    
    trainer = AutoModelTrainer(
        csv_dir=args.csv_dir,
        json_dir=args.json_dir,
        output_dir=args.output_dir
    )
    
    # D√©tecter automatiquement le mod√®le existant, sauf si --fresh_start est sp√©cifi√©
    model_path = args.model_path
    
    if not args.fresh_start and not model_path:
        # Chercher le mod√®le dans les emplacements par d√©faut
        base_dir = os.path.dirname(os.path.abspath(__file__))
        default_paths = [
            os.path.join(base_dir, 'data', 'motion_model.pth'),
            os.path.join(base_dir, 'data', 'training_viz', 'motion_model.pth')
        ]
        
        for path in default_paths:
            if os.path.exists(path):
                model_path = path
                print(f"\nüì¶ Mod√®le existant d√©tect√©: {path}")
                print("   ‚îó L'entra√Ænement continuera √† partir de ce mod√®le")
                break
    
    trainer.run_full_pipeline(
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        use_gpu=not args.cpu,
        model_path=model_path
    )
    
    print("\nüëã Programme termin√©.")

if __name__ == "__main__":
    main()